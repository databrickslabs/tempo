[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "Tempo"
dynamic = ["version"]
description = 'Tempo is timeseries manipulation for Spark. This project builds upon the capabilities of PySpark to provide a suite of abstractions and functions that make operations on timeseries data easier and highly scalable.'
readme = "README.md"
requires-python = ">=3.9"
license = "MIT"
keywords = []
authors = [
  { name = "Lorin Dawson", email = "lorin.dawson@databricks.com" },
  { name = "Kevin Wang", email = "k.wang@databricks.com" },
  { name = "Hector Bustamante", email = "hector.bustamante@databricks.com" }
]
classifiers = [
  "Development Status :: 4 - Beta",
  "Programming Language :: Python",
  "Programming Language :: Python :: 3.9",
  "Programming Language :: Python :: 3.10",
  "Programming Language :: Python :: 3.11",
  "Programming Language :: Python :: 3.12",
  "Programming Language :: Python :: Implementation :: CPython",
  "Programming Language :: Python :: Implementation :: PyPy",
]
dependencies = []

[tool.hatch.version]
source = "code"
path = "./version.py"

[project.urls]
Documentation = "https://databrickslabs.github.io/tempo/"
Issues = "https://github.com/databrickslabs/tempo/issues"
Source = "https://github.com/databrickslabs/tempo"


[tool.hatch.scripts]
testAll = [
  "hatch run dbr154:test",
  "hatch run dbr143:test",
  "hatch run dbr133:test",
  "hatch run dbr122:test",
  "hatch run dbr113:test"
]

[tool.hatch.envs.testenv]
template = "testenv"
dependencies = [
  "pip>=23,<24",
  "chispa>=0.10,<1",
  "coverage>=7,<8",
  "jsonref>=1,<2",
  "packaging>=24,<25",
  "python-dateutil>=2,<3"
]

[tool.hatch.envs.testenv.scripts]
test = [
  "coverage erase",
  "coverage run -m unittest discover -s tests -p '*_tests.py'"
]

[tool.hatch.envs.dbr154]
template = "testenv"
python = "3.11"
extra-dependencies = [
  "delta-spark~=3.2.0",
  "ipython~=8.15.0",
  "numpy~=1.23.5",
  "pandas~=1.5.3",
  "pyarrow~=14.0.1",
  "pyspark~=3.5.0",
  "scipy~=1.11.1"
]

[tool.hatch.envs.dbr143]
template = "testenv"
python = "3.10"
extra-dependencies = [
  "delta-spark~=3.1.0",
  'ipython~=8.14.0',
  'numpy~=1.23.5',
  'pandas~=1.5.3',
  'pyarrow~=8.0.0',
  'pyspark~=3.5.0',
  'scipy~=1.10.0'
]

[tool.hatch.envs.dbr133]
template = "testenv"
python = "3.10"
extra-dependencies = [
  'delta-spark~=2.4.0',
  'ipython~=8.10.0',
  'numpy~=1.21.5',
  'pandas~=1.4.4',
  'pyarrow~=8.0.0',
  'pyspark~=3.4.1',
  'scipy~=1.9.1'
]

[tool.hatch.envs.dbr122]
template = "testenv"
python = "3.9"
extra-dependencies = [
  'delta-spark~=2.2.0',
  'ipython~=8.5.0',
  'numpy~=1.21.5',
  'pandas~=1.4.2',
  'pyarrow~=7.0.0',
  'pyspark~=3.3.2',
  'scipy~=1.7.3'
]

[tool.hatch.envs.dbr113]
template = "testenv"
python = "3.9"
extra-dependencies = [
  'delta-spark~=2.1.0',
  'ipython~=7.32.0',
  'numpy~=1.20.3',
  'pandas~=1.3.4',
  'pyarrow~=7.0.0',
  'pyspark~=3.3.0',
  'scipy~=1.7.1'
]

[tool.hatch.envs.lint]
template = "testenv"
skip-install = true
dependencies = [
  "flake8",
  "black==24.4.1"
]

[tool.hatch.envs.lint.scripts]
runLint = [
  "black --check --diff ./tempo",
  "flake8 --config ./.flake8 ./tempo"
]

[tool.hatch.envs.type-check]
template = "testenv"
skip-install = true
dependencies = [
  "mypy>=1,<2",
  "pandas-stubs>=2,<3",
  "numpy",
  "types-openpyxl"
]

[tool.hatch.envs.type-check.scripts]
check = "mypy --install-types --non-interactive ./tempo"


[tool.hatch.envs.build-dist]
template = "testenv"
skip-install = true
dependencies = [
  "build",
  "semver"
]

[tool.hatch.envs.build-dist.scripts]
build = "python setup.py clean bdist_wheel"


[tool.hatch.envs.build-docs]
# TODO: making this dynamic is difficult in tox, so for now we will just use the latest version
# We should have a top-level makefile that orchestrates this which allows better environment prep and execution of
# shell scripts prior to tox execution. it'll also create a stable interface for migrating to hatch in the future
# since the make commands would not change
template = "testenv"
skip-install = true
python = "3.10"
extra-dependencies = [
  "delta-spark~=3.2.0",
  "ipython~=8.15.0",
  "numpy~=1.23.5",
  "pandas~=1.5.3",
  "pyarrow~=14.0.1",
  "pyspark~=3.5.0",
  "scipy~=1.11.1",
  "sphinx-autobuild",
  "sphinx-copybutton",
  "sphinx",
  "sphinx-design",
  "sphinx-panels",
  "furo",
  "semver"
]


[tool.hatch.envs.build-docs.scripts]
build = "make --directory ../docs html"


[tool.hatch.envs.coverage-report]
template = "testenv"
skip-install = true
extra-dependencies = [
  "coverage>=7,<8"
]


[tool.hatch.envs.coverage-report.env-vars]
COVERAGE_FILE = ".coverage"

[tool.hatch.envs.coverage-report.scripts]
run-coverage = [
  "coverage combine",
  "coverage report -m",
  "coverage xml"
]
