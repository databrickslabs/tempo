import copy
from functools import reduce
from typing import Callable, List, Optional, Union

import pandas as pd
import pyspark.sql.functions as sfn
from pyspark import __version__ as pyspark_version
from pyspark.sql import Window
from pyspark.sql.types import DateType, NumericType, TimestampType

from tempo.tsdf import TSDF
from tempo.tsschema import ParsedTSIndex, SimpleTSIndex

# Check PySpark version for compatibility
PYSPARK_VERSION = tuple(int(x) for x in pyspark_version.split(".")[:2])
HAS_COUNT_IF = PYSPARK_VERSION >= (3, 5)
HAS_BOOL_OR = PYSPARK_VERSION >= (3, 5)

# Interpolation fill options
method_options = ["zero", "null", "bfill", "ffill", "linear"]


def _bool_or_compat(col):
    """Compatibility wrapper for bool_or function"""
    if HAS_BOOL_OR:
        return sfn.bool_or(col)
    else:
        # Fallback for PySpark < 3.5: max(cast(condition as int))
        # col can be either a string or a Column object
        if isinstance(col, str):
            col_expr = sfn.col(col)
        else:
            col_expr = col
        # Return max which will be 1 for True or 0/null for False
        # We don't add > 0 here because that needs to be done after the window function
        return sfn.max(col_expr.cast("int"))


# Some common interpolation functions


def zero_fill(null_series: pd.Series) -> pd.Series:
    return null_series.fillna(0)


def forward_fill(null_series: pd.Series) -> pd.Series:
    return null_series.ffill()


def backward_fill(null_series: pd.Series) -> pd.Series:
    return null_series.bfill()


# The interpolation


def _is_valid_method_for_column(tsdf: TSDF, method: str, col_name: str) -> bool:
    """
    zero and linear interpolation are only valid for numeric columns
    """
    if method in ["linear", "zero"]:
        return isinstance(tsdf.df.schema[col_name].dataType, NumericType)
    else:
        return True


def _build_interpolator(
    interpol_cols: List[str],
    interpol_fn: Union[Callable[[pd.Series], pd.Series], str],
    ts_col: Optional[str] = None,
) -> Callable[[pd.DataFrame], pd.DataFrame]:
    def interpolator_fn(pdf: pd.DataFrame) -> pd.DataFrame:
        # create a timestamp index
        if ts_col:
            pdf.index = pd.to_datetime(pdf[ts_col])
        # mask for rows that need interpolation
        num_rows = pdf.shape[0]
        any_interpol_mask = pd.Series([False] * num_rows, index=pdf.index)
        # interpolate each column
        for interpol_col in interpol_cols:
            # those rows that need interpolation
            any_interpol_mask = any_interpol_mask | pdf[interpol_col].isna()

            # otherwise we interpolate the missing values
            if isinstance(interpol_fn, str):
                # Only use pandas interpolate for methods it supports
                if interpol_fn in ["linear"]:
                    # Note: pandas linear interpolation by default uses limit_direction='forward'
                    # This means:
                    # - Missing values between known values are linearly interpolated
                    # - Missing values at the end (with no following value) are forward-filled with the last known value
                    # - Missing values at the beginning (with no preceding value) remain as NaN
                    pdf[interpol_col] = pdf[interpol_col].interpolate(
                        method=interpol_fn
                    )
                elif interpol_fn == "ffill":
                    pdf[interpol_col] = pdf[interpol_col].ffill()
                elif interpol_fn == "bfill":
                    pdf[interpol_col] = pdf[interpol_col].bfill()
                elif interpol_fn == "zero":
                    pdf[interpol_col] = pdf[interpol_col].fillna(0)
                elif interpol_fn == "null":
                    # null means leave as null, so do nothing
                    pass
            else:
                pdf[interpol_col] = interpol_fn(pdf[interpol_col])
        # return only the rows that were missing (others are margins)
        return pdf[any_interpol_mask]

    return interpolator_fn


def interpolate(
    tsdf: TSDF,
    cols: Union[str, List[str]],
    fn: Union[Callable[[pd.Series], pd.Series], str],
    leading_margin: int = 1,
    lagging_margin: int = 0,
) -> TSDF:
    """
    Interpolate missing values in a time series column.

    For the given column, null values are assumed to be missing, and
    this method will attempt to interpolate them using the given function.
    The interpolation function can be a string representing a valid method
    for the pandas Series.interpolate method, or a custom function that takes
    a pandas Series and returns a pandas Series of the same length.
    The Series given may include a "margin" of
    leading or trailing non-missing (i.e. non-null) values to help the
    interpolation function. The exact size of the leading and trailing margins are
    configurable. Only values of the missing values generated by the interpolation
    function are merged back into the original time series (so changes to margins or other
    non-null values will not be ignored in the final result).

    **Note**: This function may cause the re-ordering of the rows in the resulting TSDF.

    **Interpolation Method Behaviors**:

    - **linear**: Uses pandas' linear interpolation. Missing values between known values
      are linearly interpolated. Missing values at the end (with no following value) are
      forward-filled with the last known value. Missing values at the beginning remain as NaN.
    - **ffill**: Forward fill - propagates last valid observation forward to fill gaps
    - **bfill**: Backward fill - propagates next valid observation backward to fill gaps
    - **zero**: Fills all missing values with 0
    - **null**: Leaves missing values as null (no interpolation)

    :param tsdf: the :class:`TSDF` timeseries dataframe
    :param cols: the names of the columns to interpolate
    :param fn: the interpolation function
    :param leading_margin: the number of non-missing values
    to include before the first missing value
    :param lagging_margin: the number of non-missing values
    to include after the last missing value

    :return: a new :class:`TSDF` with the missing values of the given
    column interpolated
    """

    # parameter normalization & validation
    if isinstance(cols, str):
        cols = [cols]
    for col in cols:
        assert (
            col in tsdf.columns
        ), f"Column to be interpolated '{col}' not found in the DataFrame"

    # validate interpolation method is in allowed options
    if isinstance(fn, str) and fn not in method_options:
        raise ValueError(
            f"Invalid interpolation method '{fn}'. Must be one of {method_options}"
        )

    # identify rows that need interpolation
    needs_intpl_col = "__tmp_needs_interpolation"
    null_col_exprs = [sfn.col(col).isNull() for col in cols]
    any_null_expr = reduce(lambda x, y: x | y, null_col_exprs)
    need_intpl = tsdf.df.withColumn(needs_intpl_col, any_null_expr)

    # identify transitions between segments
    seg_trans_col = "__tmp_seg_transition"
    all_win = tsdf.baseWindow()
    segments = need_intpl.withColumn(
        seg_trans_col,
        sfn.lag(needs_intpl_col, 1, False).over(all_win) != sfn.col(needs_intpl_col),
    )

    # assign a group number to each segment
    seg_group_col = "__tmp_seg_group"
    all_prev_win = tsdf.allBeforeWindow()

    # Use count_if if available (PySpark 3.5+), otherwise use sum with cast
    if HAS_COUNT_IF:
        segments = segments.withColumn(
            seg_group_col, sfn.count_if(seg_trans_col).over(all_prev_win)
        )
    else:
        # Fallback for PySpark < 3.5: sum(cast(condition as int))
        segments = segments.withColumn(
            seg_group_col,
            sfn.sum(sfn.col(seg_trans_col).cast("int")).over(all_prev_win),
        )

    # build margins around intepolation segments
    if leading_margin > 0 or lagging_margin > 0:
        # identify rows in the leading margin
        leading_margin_col = "__tmp_leading_margin"
        margin_win = tsdf.rowsBetweenWindow(1, leading_margin)
        lead_margins = segments.withColumn(
            leading_margin_col,
            sfn.when(
                ~sfn.col(needs_intpl_col)
                & (
                    _bool_or_compat(seg_trans_col).over(margin_win)
                    if HAS_BOOL_OR
                    else (_bool_or_compat(seg_trans_col).over(margin_win) > 0)
                ),
                sfn.array(sfn.col(seg_group_col), sfn.col(seg_group_col) + 1),
            ).otherwise(sfn.array(sfn.col(seg_group_col))),
        )
        # identify rows in the lagging margin
        lagging_margin_col = "__tmp_lagging_margin"
        margin_win = tsdf.rowsBetweenWindow(-max(0, lagging_margin - 1), 0)
        lag_margins = lead_margins.withColumn(
            lagging_margin_col,
            sfn.when(
                ~sfn.col(needs_intpl_col)
                & (
                    _bool_or_compat(seg_trans_col).over(margin_win)
                    if HAS_BOOL_OR
                    else (_bool_or_compat(seg_trans_col).over(margin_win) > 0)
                ),
                sfn.array(sfn.col(seg_group_col) - 1, sfn.col(seg_group_col)),
            ).otherwise(sfn.array(sfn.col(seg_group_col))),
        )
        # collect the group number of each segment with a margin
        margin_col = "__tmp_group_with_margin"
        all_margins = lag_margins.withColumn(
            margin_col,
            sfn.array_union(sfn.col(leading_margin_col), sfn.col(lagging_margin_col)),
        )
        # explode the groups with margins
        explode_exprs = tsdf.columns + [
            needs_intpl_col,
            sfn.explode(margin_col).alias(seg_group_col),
        ]
        segments = all_margins.select(*explode_exprs)

    # identify segments that need interpolation
    group_by_cols = tsdf.series_ids + [seg_group_col]
    segment_win = Window.partitionBy(group_by_cols)
    if HAS_BOOL_OR:
        segments = segments.withColumn(
            needs_intpl_col, _bool_or_compat(sfn.col(needs_intpl_col)).over(segment_win)
        )
    else:
        # For older PySpark, we need to convert back to boolean
        segments = segments.withColumn(
            needs_intpl_col,
            (_bool_or_compat(sfn.col(needs_intpl_col)).over(segment_win) > 0),
        )

    # split the segments according to the need for interpolation
    needs_interpol = segments.where(needs_intpl_col)
    no_interpol = segments.where(~sfn.col(needs_intpl_col))

    # enable pandas timeseries indexing if possible
    ts_col = None
    if tsdf.ts_index.has_types(TimestampType) or tsdf.ts_index.has_types(DateType):
        if isinstance(tsdf.ts_index, SimpleTSIndex):
            ts_col = tsdf.ts_index.colname
        elif isinstance(tsdf.ts_index, ParsedTSIndex):
            ts_col = tsdf.ts_index.parsed_ts_field

    # Validate column types before building the interpolator
    if isinstance(fn, str):
        for col in cols:
            if not _is_valid_method_for_column(tsdf, fn, col):
                raise ValueError(
                    f"Interpolation method '{fn}' is not supported for column "
                    f"'{col}' of type '{tsdf.df.schema[col].dataType}'. "
                    f"Only NumericType columns are supported."
                )

    # build the interpolator function
    interpolator = _build_interpolator(cols, fn, ts_col)

    # apply the interpolator to each segment
    interpolated_df = needs_interpol.groupBy(group_by_cols).applyInPandas(
        interpolator, needs_interpol.schema
    )

    # merge the interpolated segments with the non-interpolated ones
    final_df = no_interpol.union(interpolated_df).drop(
        seg_group_col, needs_intpl_col, seg_trans_col
    )

    # return it as a new TSDF
    return TSDF(final_df, ts_schema=copy.deepcopy(tsdf.ts_schema))
